# 2023-02-20

# Ulozenie analyzy velkeho poctu entries (vytvarame tree resp. histo)

1) tree = TTree, TNtuple
* standardny sposob, priprava medzi-vysledku a potom finalne histogram-ovanie
* podstatna nevyhoda, cim vacsi pocet analyzovanych entries, tym vacsi subor + narocnejsie
* tree po naplneni urciteho buffera (by default) sa uklada na storage
* v podstate "nepotrebuju" CPU, len stream-uju entries

2) histo = TH1, TH2, TH3, THn, THnSparse
* histogramy maju urcitu specificku velkost, ktora NEZAVISI od poctu analyzovanych entries
* ich velkost zavisi len od poctu axis a bins (tabulka 1, 2, 3, n-rozmerna)
* histo su pocas celej analyzy v pamati a az na konci analyzy sa ukladaju na storage
* CPU narocnejsie, pre kazde jedno entry vzdy potrebujem najst bin

Je vhodnejsie robit analyzu pomocou tree, poskytuju velku variabilitu pri finalnej analyze.
Problem nastava pri velkom pocte entries, kedy tree-subor moze mat mega rozmery. Prave vtedy
sme "nuteni" pouzit histo.

histo ~ de facto tree, kde vzdy "zaokruhlim" hodnotu na bin a pamatam si len jeho pocetnost,
radikalne zmensenie, 10.000.000 hodnot vs 1000 hodnot (1 axis a 1000 binov). Problem s histo
zacina so zvacsovanim poctu axis a poctu binov. Vsetko potrebujem mat v pamati.

# Problem s histo->Fill

Principalny PROBLEM s plnenim histo, ak mi raz staci pamat len na 100.000 hodnot (nepodstatne
ci je to TH1, TH2, TH3, THn, THnSparse) a potrebujem pracovat s 500.000 hodnotami, tak musim
rozbit min. na 5 x 100.000 hodnot, resp. na 5 suborov. Taketo histogramy (z 5 suborov
po 100.000 hodnot) principialne NEMOZEM z-merge-ovat (pamat mam stale len na 100.0000 hodnot).

# TH1, TH2, TH3, THn vs. THnSparse
TH2 (2 osi) 100x100 binov = potrebuje vzdy pamat na 10.000 hodnot, ci bude histogram polo-prazdny,
ci pre-analyzujem male alebo obrovske mnozstvo entries

THn (5 osi) 100x100x100x100x100 binov = potrebuje vzdy pamat na 10.000.000.000 hodnot, ci bude
histogram polo-prazdny, ci pre-analyzujem male alebo obrovske mnozstvo entries

THnSparse (5 osi) 100x100x100x100x100 binov = vopred neviem kolko hodnot budem potrebovat,
podla potreby sa vzdy potrebny bin vytvori, az ked je realne potrebny, na rozdiel od TH1, TH2, THn,
kedy sa vsetky bins vopred alokuju.

Inymi slovami, ak mam TH2 100x100 bins, vzdy potrebujem 10.000 hodnot v pamati, aj ked mam
zaplnenych len zopar binov, tie nezaplnene bins maju hodnotu 0, ktora su tiez v pamati. Ale ak
mam THnSparse 100x100 bins, tak v pamati su len tie bin hodnoty, ktore su realne zaplnene
(toto nie je uplne pravda, ale pre teraz nepodstatne), resp. THnSparse si "nepamata" bins
s hodnotou 0 ("sparse" = zriedkavy, roztruseny). Cim je TH2 "plnsie" zaplneny, tym sa rozdiel
medzi TH2 a THnSparse straca.

Cim vacsi pocet osi a vacsi pocet binov, tym pomer skutocne "potrebnych" a "nepotrebnych" binov
sa moze radikalne zvacsovat !!! a preto to aj ROOT vyspekuloval a implementoval.

# konkretny priklad s THnSparse
https://eos.ndmspc.io/eos/ndmspc/scratch/alice.cern.ch/user/a/alitrain/PWGLF/LF_pp_AOD/987/phi_leading_3s/AnalysisResults.root

THnSparseT<TArrayF> (*0x55693be47770): "Mixing" ""
  6 dimensions, 6.48798e+07 entries in 3547947 filled bins
    axis 0 "": 95 bins (0.985..1.08), variable bin sizes
    axis 1 "": 10 bins (0..10), variable bin sizes
    axis 2 "": 10 bins (0..100), variable bin sizes
    axis 3 "": 36 bins (-1.5708..4.71239), variable bin sizes
    axis 4 "": 15 bins (0..30), variable bin sizes
    axis 5 "": 16 bins (-1.6..1.6), variable bin sizes

95*10*10*36*15*16 = 82.080.000 bins !!! ALE LEN !!! 3.547.947 filled bins !!!
Ak by to bol obycajny THn so 6 osami a rovnakym poctom bins, tak potrebujem pamat
na 82.080.000 hodnot, na rozdiel od THnSparse, ktory potrebuje pamat len na 3.547.947 hodnot,
t.j. (ne)pomer skutocne "potrebnych" a "nepotrebnych" binov je obrovsky

Dalej budeme uvazovat tento priklad + predpokladame, ze nase PC ma max. pamat na 4.000.000 hodnot.

# problem 1
Analyza konci s tym, ze out of memory, resp. nas THnSparse nevosiel do pamate.

Riesenie, budeme kontrolovat pocet filled bins. Ak sa priblizi ku kritickej hodnote, napr. tych
vyssie spomenutych 4.000.000 hodnot, tak THnSparse ulozime, vymazeme z pamate a vytvorime dalsi,
novy THnSparse. POZOR, tieto THnSparse na nasom PC (max. 4.000.000 hodnot) principialne nebude
vediet z-merge-ovat ako celok, co s tym, vid nizsie.

# problem 2
Analyza presla, ideme merge-ovat THnSparse (z roznych workers), ale znova problem out of memory.

Predpokladajme THnSparse1 z worker1 ma 3.547.947 filled bins a nech napr. THnSparse2 z worker2
ma 3.400.000 filled bins.

V com je problem ? Aj ked THnSparse2 ma o nieco menej filled bins ako THnSparse1, to vobec
neznamena, ze vysledny z-merge-ovany THnSparse bude mat priblizne rovnaky pocet filled bins.
Vsetko zavisi od toho, nakolko sa filled bins z dvoch roznych THnSparse budu "prekryvat",
resp. budu identicke. Ak by filled bins z obidvoch THnSparse boli identicke, tak vysledny
THnSparse nebude mat viac ako 3.547.947 filled bins (a teda nenastal by vobec problem out of
memory pri merge-ovanim).

Podstatne vacsia pravdepodobnost je, ze pri merge-ovani THnSparse1 (3.547.947 filled bins)
a THnSparse2 (3.400.000 filled bins), bude vysledny THnSparse mat napr. 4.500.000 filled bins,
co prave sposobi problem out of memory (nase PC ma max. 4.000.000 hodnot).

Teoreticky je mozne, ze vysledny THnSparse bude potrebovat az 6.947.947 filled bins, ak by
v oboch THnSparse boli jedinecne, neopakovatelne bins. Ale stale je to radikalne menej
ako 95*10*10*36*15*16 = 82.080.000 bins v pripade THn.

Aka je teda riesenie ?
1) Principialne ak raz ma nase PC max. 4.000.000 hodnot, nemozeme THnSparse z-merge-ovat.
   Mozeme ale zmenit (zmensit) binning, resp. pracovat nie so vsetkymi osami sucasne,
   ale len s vybranymi. Potom budeme moct pracovat priamo z THnSparse, ale "len okliestenym".

2) Kopirujeme subory na PC s vacsou RAM, tam je velka pravdepodobnost, ze sa nam podari
   THnSparse z-merge-ovat.

3) Prevedieme THnSparse na TTree, univerzalne riesenie.

# THnSparse -> TTree
